{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........................................................................................................................................................"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import prophet\n",
    "import glob\n",
    "import datetime as dt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0 - Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Original data (2021 Dec version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot assemble with duplicate keys",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1604/1776252902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cat.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'FY Year'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Units'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Quantity'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_assemble_from_unit_mappings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    891\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, tz)\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot assemble with duplicate keys\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;31m# replace passed unit with _unit_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot assemble with duplicate keys"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for f in glob.glob(\"../IV Sets Clean data/*.xlsx\"):\n",
    "    df = pd.read_excel(f)\n",
    "    data = data.append(df,ignore_index=True)\n",
    "data = data[data['Cat.'].str.contains('Set')]\n",
    "data=data.rename(columns={'FY Year':'Date','Units':'Quantity'})\n",
    "data['Date']=pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select top 10 skus (high runners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_summary=data[data['Date']<\"2021-12-01\"].groupby(['SAP SKU'])['Quantity'].agg([('total_orders','sum')]).reset_index()\n",
    "sku_summary['rank']=sku_summary['total_orders'].rank(method='dense',ascending=False)\n",
    "sku_summary=sku_summary.sort_values(by=['total_orders'],ascending=False)\n",
    "top_10 = list(sku_summary['SAP SKU'][sku_summary['rank']<=10])\n",
    "sku_summary.head(10) # display top 10, high runners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - SKU level forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical data at SKU level\n",
    "historical_data=data[data['SAP SKU'].isin(top_10)].groupby(['SAP SKU','Date'])['Quantity'].agg([('Quantity','sum')]).reset_index()\n",
    "sns.relplot(\n",
    "    data=historical_data,\n",
    "    x=\"Date\", y=\"Quantity\",col='SAP SKU',col_wrap=3,kind='line',facet_kws=dict(sharey=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see above the historical signal for each sku. We will highlight high peaks and drops and trends changes so that we can incorporate them into the prophet model to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[['peak','drop']]=0\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='60593') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\",\"2020-04-01\",\"2020-10-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='60593') & \n",
    "                          (historical_data['Date'].isin([\"2020-05-01\",\"2020-06-01\",\"2020-07-01\",\"2020-08-01\",\n",
    "                                            \"2021-02-01\",\"2021-07-01\",\"2021-08-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='G30402M') & \n",
    "                          (historical_data['Date'].isin([\"2018-04-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='273-004V') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\",\"2021-05-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='273-004V') & \n",
    "                          (historical_data['Date'].isin([\"2020-05-01\",\"2021-02-01\",\"2021-03-01\",\n",
    "                                            \"2021-07-01\",\"2021-08-01\",\"2021-09-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='2420-0007') & \n",
    "                          (historical_data['Date'].isin([\"2021-09-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='60693E') & \n",
    "                          (historical_data['Date'].isin([\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='60693E') & \n",
    "                          (historical_data['Date'].isin([\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='72504EB') & \n",
    "                          (historical_data['Date'].isin([\"2019-05-01\",\"2020-06-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='72504EB') & \n",
    "                          (historical_data['Date'].isin([\"2021-08-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='G30302M') & \n",
    "                          (historical_data['Date'].isin([\"2021-03-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='G30302M') & \n",
    "                          (historical_data['Date'].isin([\"2021-06-01\",\"2021-07-01\",\"2021-08-01\",\"2021-09-01\",\"2021-10-01\",\"2021-11-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='72304B') & \n",
    "                          (historical_data['Date'].isin([\"2019-01-01\",\"2020-04-01\",\"2020-12-01\",\"2021-06-01\",\"2021-07-01\",\"2021-11-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='72304B') & \n",
    "                          (historical_data['Date'].isin([\"2020-05-01\",\"2020-08-01\",\"2020-09-01\",\"2021-03-01\",\"2021-04-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='60093E') & \n",
    "                          (historical_data['Date']<=\"2017-09-01\") &\n",
    "                          (historical_data['Date']>=\"2016-10-01\") \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='60093E') & \n",
    "                          (historical_data['Date'].isin([\"2021-03-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use prophet model with special events as regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(material,snapshot_date=pd.to_datetime(\"2021-12-01\"),h=24):\n",
    "    \n",
    "    original_data=historical_data.copy()\n",
    "    original_data = original_data[((original_data['SAP SKU']==material) &\n",
    "                                    (original_data['Date']<snapshot_date))]\n",
    "    \n",
    "    if material==\"72304B\":\n",
    "      original_data = original_data[original_data['Date']>=\"2017-03-01\"]\n",
    "    elif material==\"72504EB\":\n",
    "      original_data = original_data[original_data['Date']>=\"2016-03-01\"]\n",
    "    \n",
    "    #whether to fit auto.seasonality (if series not intermittent)\n",
    "    zeros=np.sum(original_data.Quantity==0)/(original_data.Quantity.shape[0])\n",
    "    if zeros<=0.4:\n",
    "      yearly=False\n",
    "    else:\n",
    "      yearly='auto'\n",
    "    \n",
    "    #define regressor functions for the prophet model\n",
    "    def peak(ds):\n",
    "      dates=pd.to_datetime(ds)\n",
    "      return original_data['peak'][original_data['Date'].isin(dates)] \n",
    "    def drop(ds):\n",
    "      dates=pd.to_datetime(ds)\n",
    "      return original_data['drop'][original_data['Date'].isin(dates)] \n",
    "    \n",
    "\n",
    "    input_data= original_data.copy()\n",
    "    input_data=input_data[['Date','Quantity']].rename(columns={'Date':'ds','Quantity':'y'})\n",
    "    \n",
    "    #fitting the different models one by one\n",
    "    input_data['drop']=drop(input_data['ds'])\n",
    "    input_data['peak']=peak(input_data['ds'])\n",
    "    model=prophet.Prophet(yearly_seasonality=yearly,weekly_seasonality = False,daily_seasonality = False)\n",
    "    model.add_regressor('drop')\n",
    "    model.add_regressor('peak')\n",
    "    model.fit(input_data)\n",
    "    forecast_timeline=model.make_future_dataframe(periods = h,freq=\"MS\")\n",
    "    forecast_timeline[['drop','peak']]=0\n",
    "    prophet_forecast=model.predict(forecast_timeline)\n",
    "\n",
    "    #consolidating the different forecasts\n",
    "    all_fcast_1 = prophet_forecast[['ds','yhat','yhat_lower','yhat_upper']][prophet_forecast['ds']>=snapshot_date]\n",
    "    all_fcast_1=all_fcast_1.rename(columns={\"ds\":\"Date\",\"yhat\":\"prophet_fcast\",\"yhat_lower\":\"prophet_lower\",\"yhat_upper\":\"prophet_upper\"})\n",
    "    all_fcast_1['prophet_fcast'][all_fcast_1['prophet_fcast']<0]=0\n",
    "    all_fcast_1['prophet_lower'][all_fcast_1['prophet_lower']<0]=0\n",
    "    all_fcast_1['prophet_upper'][all_fcast_1['prophet_upper']<0]=0\n",
    "    all_fcast_1['series_type']=\"regular\"\n",
    "    all_fcast_1['input_category']=\"original_with_regressors\"\n",
    "    all_fcast_1['SAP.SKU']=material\n",
    "    all_fcast_1['Snapshot']=pd.to_datetime(snapshot_date)\n",
    "      \n",
    "    return all_fcast_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#material=top_10[1]\n",
    "#generate_stats(material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_snapshot= dt.datetime.today().replace(minute=0, hour=0, second=0, microsecond=0,day=1)\n",
    "all_stats=[]\n",
    "for material in top_10:\n",
    "    all_stats=all_stats+[generate_stats(material=material,snapshot_date=pd.to_datetime(this_snapshot))]\n",
    "all_stats=pd.concat(all_stats,ignore_index=True)\n",
    "all_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the results for the sku level forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical_data.to_excel(\"./stats_output/sku_level/historical_data_\"+this_snapshot+\".xlsx\",index=False)\n",
    "all_stats.to_excel(\"../Emea_high_runner_SKUlvl.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate stats for the past few snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snapshots = pd.date_range(start=\"2021-07-01\",end=\"2021-11-01\",freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(.........might take time to run: can be improved with apply/high perf computing etc .............)\n",
    "#all_stats=[]\n",
    "#for snapshot in snapshots:\n",
    "#    for material in top_10:\n",
    "#        all_stats=all_stats+[generate_stats(material=material,snapshot_date=snapshot)]\n",
    "#all_stats=pd.concat(all_stats,ignore_index=True)\n",
    "#all_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_stats.to_excel(\"./stats_output/sku_level/generated_forecast_previous_snapshots.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Sku & Cluster level forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the input data by identifying start date and end date to focus on relevant signals to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data=data[ (data['SAP SKU'].isin(top_10)) & (data['Cluster'].notnull())]\n",
    "historical_data=historical_data.groupby(['SAP SKU','Cluster','Date'])['Quantity'].agg([('Quantity','sum')]).reset_index()\n",
    "\n",
    "max_date=max(historical_data['Date']) - pd.DateOffset(months=18) # to filter out series with no demand for the last 18 months\n",
    "\n",
    "temp = historical_data[historical_data['Quantity']!=0].groupby(['SAP SKU','Cluster'])['Date'].agg([('start_date','min'),('end_date','max')]).reset_index()\n",
    "\n",
    "historical_data = historical_data.merge(temp,how='left')\n",
    "historical_data = historical_data[historical_data['start_date'].notnull()] #remove null signals\n",
    "\n",
    "historical_data = historical_data[historical_data['Date']>=historical_data['start_date']] # re-frame each time series\n",
    "historical_data = historical_data[historical_data['end_date']>=max_date] # consider we no longer have demand if no demand since the last 18 months\n",
    "\n",
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add peaks and drops noticed at sku level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[['peak','drop']]=0\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='60593') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\",\"2020-04-01\",\"2020-10-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='60593') & \n",
    "                          (historical_data['Date'].isin([\"2020-05-01\",\"2020-06-01\",\"2020-07-01\",\"2020-08-01\",\n",
    "                                            \"2021-02-01\",\"2021-07-01\",\"2021-08-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='G30402M') & \n",
    "                          (historical_data['Date'].isin([\"2018-04-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='273-004V') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\",\"2021-05-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='273-004V') & \n",
    "                          (historical_data['Date'].isin([\"2020-05-01\",\"2021-02-01\",\"2021-03-01\",\n",
    "                                            \"2021-07-01\",\"2021-08-01\",\"2021-09-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='2420-0007') & \n",
    "                          (historical_data['Date'].isin([\"2021-09-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='60693E') & \n",
    "                          (historical_data['Date'].isin([\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='60693E') & \n",
    "                          (historical_data['Date'].isin([\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='72504EB') & \n",
    "                          (historical_data['Date'].isin([\"2019-05-01\",\"2020-06-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='72504EB') & \n",
    "                          (historical_data['Date'].isin([\"2021-08-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='G30302M') & \n",
    "                          (historical_data['Date'].isin([\"2021-03-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='G30302M') & \n",
    "                          (historical_data['Date'].isin([\"2021-06-01\",\"2021-07-01\",\"2021-08-01\",\"2021-09-01\",\"2021-10-01\",\"2021-11-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='72304B') & \n",
    "                          (historical_data['Date'].isin([\"2019-01-01\",\"2020-04-01\",\"2020-12-01\",\"2021-06-01\",\"2021-07-01\",\"2021-11-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='72304B') & \n",
    "                          (historical_data['Date'].isin([\"2020-05-01\",\"2020-08-01\",\"2020-09-01\",\"2021-03-01\",\"2021-04-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['SAP SKU']=='60093E') & \n",
    "                          (historical_data['Date']<=\"2017-09-01\") &\n",
    "                          (historical_data['Date']>=\"2016-10-01\") \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['SAP SKU']=='60093E') & \n",
    "                          (historical_data['Date'].isin([\"2021-03-01\",\"2021-09-01\",\"2021-10-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add peaks and drops noticed at cluster level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='Arab Peninsula') & \n",
    "                          (historical_data['Date'].isin([\"2021-08-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='BNL') & \n",
    "                          (historical_data['Date'].isin([\"2017-08-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='IB') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='CEE') & \n",
    "                          (historical_data['Date'].isin([\"2020-11-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['drop'][( (historical_data['Cluster']=='FR') & \n",
    "                          (historical_data['Date']>=\"2020-04-01\") &\n",
    "                          (historical_data['SAP SKU']==\"273-004V\")\n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='GSA') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\",\"2021-09-01\"])) \n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='ISR') & \n",
    "                          (historical_data['Date'].isin([\"2017-11-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['Cluster']=='ISR') & \n",
    "                          (historical_data['Date']<=\"2018-08-01\") &\n",
    "                          (historical_data['Date']>=\"2018-01-01\")\n",
    "                        )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='IT') & \n",
    "                          (historical_data['Date'].isin([\"2020-03-01\",\"2021-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['Cluster']=='IT') & \n",
    "                          (historical_data['Date'].isin([\"2021-08-01\",\"2021-09-01\",\"2021-10-01\"]))\n",
    "                         )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='NOR') & \n",
    "                          (historical_data['Date'].isin([\"2021-11-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['Cluster']=='NOR') & \n",
    "                          (historical_data['Date'].isin([\"2021-08-01\",\"2021-09-01\"]))\n",
    "                         )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='Saudi Arabia') & \n",
    "                          (historical_data['Date'].isin([\"2018-04-01\"])) \n",
    "                        )]=1\n",
    "historical_data['drop'][( (historical_data['Cluster']=='Saudi Arabia') & \n",
    "                          (historical_data['Date']<=\"2019-03-01\") &\n",
    "                          (historical_data['Date']>=\"2018-05-01\")\n",
    "                         )]=1\n",
    "#......................................................................................................................\n",
    "historical_data['peak'][( (historical_data['Cluster']=='UK') & \n",
    "                          (historical_data['Date'].isin([\"2020-10-01\",\"2020-11-01\"])) \n",
    "                        )]=1\n",
    "historical_data['peak'][( (historical_data['Cluster']=='UK') & \n",
    "                          (historical_data['Date'].isin([\"2020-04-01\",\"2021-04-01\"])) \n",
    "                        )]=2\n",
    "historical_data['drop'][( (historical_data['Cluster']=='UK') & \n",
    "                          (historical_data['Date'].isin([\"2020-08-01\",\"2021-02-01\"]))\n",
    "                         )]=1\n",
    "historical_data['drop'][( (historical_data['Cluster']=='UK') & \n",
    "                          (historical_data['Date'].isin([\"2021-07-01\",\"2021-08-01\",\"2021-09-01\",\"2021-10-01\"]))\n",
    "                         )]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats2(material,cluster,snapshot_date=pd.to_datetime(\"2021-12-01\"),h=24):\n",
    "    \n",
    "    original_data=historical_data.copy()\n",
    "    original_data = original_data[((original_data['SAP SKU']==material) &\n",
    "                                   (original_data['Cluster']==cluster) &\n",
    "                                    (original_data['Date']<snapshot_date))]\n",
    "    \n",
    "    if material==\"72304B\":\n",
    "      original_data = original_data[original_data['Date']>=\"2017-03-01\"]\n",
    "    elif material==\"72504EB\":\n",
    "      original_data = original_data[original_data['Date']>=\"2016-03-01\"]\n",
    "    \n",
    "    #whether to fit auto.seasonality (if series not intermittent)\n",
    "    zeros=np.sum(original_data.Quantity==0)/(original_data.Quantity.shape[0])\n",
    "    if zeros<=0.4:\n",
    "      yearly=False\n",
    "    else:\n",
    "      yearly='auto'\n",
    "    \n",
    "    #define regressor functions for the prophet model\n",
    "    def peak(ds):\n",
    "      dates=pd.to_datetime(ds)\n",
    "      return original_data['peak'][original_data['Date'].isin(dates)] \n",
    "    def drop(ds):\n",
    "      dates=pd.to_datetime(ds)\n",
    "      return original_data['drop'][original_data['Date'].isin(dates)] \n",
    "    \n",
    "\n",
    "    input_data= original_data.copy()\n",
    "    input_data=input_data[['Date','Quantity']].rename(columns={'Date':'ds','Quantity':'y'})\n",
    "    \n",
    "    input_data['drop']=drop(input_data['ds'])\n",
    "    input_data['peak']=peak(input_data['ds'])\n",
    "    model=prophet.Prophet(yearly_seasonality=yearly,weekly_seasonality = False,daily_seasonality = False)\n",
    "    model.add_regressor('drop')\n",
    "    model.add_regressor('peak')\n",
    "    model.fit(input_data)\n",
    "    forecast_timeline=model.make_future_dataframe(periods = h,freq=\"MS\")\n",
    "    forecast_timeline[['drop','peak']]=0\n",
    "    prophet_forecast=model.predict(forecast_timeline)\n",
    "\n",
    "    #consolidating the different forecasts\n",
    "    all_fcast_1 = prophet_forecast[['ds','yhat','yhat_lower','yhat_upper']][prophet_forecast['ds']>=snapshot_date]\n",
    "    all_fcast_1=all_fcast_1.rename(columns={\"ds\":\"Date\",\"yhat\":\"prophet_fcast\",\"yhat_lower\":\"prophet_lower\",\"yhat_upper\":\"prophet_upper\"})\n",
    "    all_fcast_1['prophet_fcast'][all_fcast_1['prophet_fcast']<0]=0\n",
    "    all_fcast_1['prophet_lower'][all_fcast_1['prophet_lower']<0]=0\n",
    "    all_fcast_1['prophet_upper'][all_fcast_1['prophet_upper']<0]=0\n",
    "    all_fcast_1['series_type']=\"regular\"\n",
    "    all_fcast_1['input_category']=\"original_with_regressors\"\n",
    "    all_fcast_1['SAP.SKU']=material\n",
    "    all_fcast_1['Cluster']=cluster\n",
    "    all_fcast_1['Snapshot']=pd.to_datetime(snapshot_date)\n",
    "      \n",
    "    return all_fcast_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_stats2(material=\"60593\",cluster=\"UK\",snapshot_date=pd.to_datetime('2021-07-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(... might take time to run: can be improved with apply/high perf computing etc ...)\n",
    "this_snapshot= dt.datetime.today().replace(minute=0, hour=0, second=0, microsecond=0,day=1)\n",
    "all_stats=[]\n",
    "for material in top_10:\n",
    "    for cluster in historical_data['Cluster'][historical_data['SAP SKU']==material].unique():\n",
    "        all_stats=all_stats+[generate_stats2(material=material,cluster=cluster,snapshot_date=pd.to_datetime(this_snapshot))]\n",
    "all_stats=pd.concat(all_stats,ignore_index=True)\n",
    "all_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical_data.to_excel(\"./stats_output/sku_x_cluster_level//historical_data_SKUxCluster_\"+this_snapshot+\".xlsx\",index=False)\n",
    "all_stats.to_excel(\"../Highrunner_Forecast/generated_forecast_SKUxCluster_\"+this_snapshot.strftime(\"%m-%d-%Y\")+\".xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate stats for the past few snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snapshots = pd.date_range(start=\"2021-07-01\",end=\"2021-11-01\",freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(....might take time to run: can be improved with apply/high perf computing etc .......)\n",
    "#all_stats=[]\n",
    "#for snapshot in snapshots:\n",
    "#    for material in top_10:\n",
    "#        for cluster in historical_data['Cluster'][historical_data['SAP SKU']==material].unique():\n",
    "#            all_stats=all_stats+[generate_stats2(material=material,cluster=cluster,snapshot_date=snapshot)]\n",
    "#all_stats=pd.concat(all_stats,ignore_index=True)\n",
    "#all_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_stats.to_excel(\"./stats_output/generated_forecast_SKUxCluster_previous_snapshots.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ....................................................................................................................................................................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
